{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d10aaa01-d57a-4679-8fcb-8481da434324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras import preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "139aee50-bb72-4bdf-a583-1d76889cf72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>category</th>\n",
       "      <th>keyword</th>\n",
       "      <th>tweet_share</th>\n",
       "      <th>quote</th>\n",
       "      <th>main_category</th>\n",
       "      <th>context_</th>\n",
       "      <th>title_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://news.livedoor.com/article/detail/20558...</td>\n",
       "      <td>2021年7月19日 19時40分</td>\n",
       "      <td>安田大サーカス・クロちゃん、新型コロナ感染　団長安田とは「別ルートでの感染と考えられます」</td>\n",
       "      <td>\\n　お笑いトリオ・安田大サーカスのクロちゃん（44）の所属事務所・松竹芸能は19日、クロち...</td>\n",
       "      <td>ニューストップ&lt;SEP&gt;芸能&lt;SEP&gt;芸能総合</td>\n",
       "      <td>クロちゃん&lt;SEP&gt;安田大サーカス&lt;SEP&gt;芸能ニュース&lt;SEP&gt;新型コロナウイルス</td>\n",
       "      <td>1025</td>\n",
       "      <td>オリコン</td>\n",
       "      <td>芸能</td>\n",
       "      <td>お笑いトリオ ・ 安田大サーカス の クロちゃん ( 44 ) の 所属事務所 ・ 松竹芸能...</td>\n",
       "      <td>安田大サーカス ・ クロちゃん 、 新型 コロナ感染 団長安田 と は 「 別 ルート で ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://news.livedoor.com/article/detail/20558...</td>\n",
       "      <td>2021年7月19日 19時32分</td>\n",
       "      <td>へずまりゅうに懲役求刑“反省みられない”</td>\n",
       "      <td>\\n元ユーチューバー、「へずまりゅう」こと原田将大被告（３０）――「（Ｑ．初公判ですがお気持...</td>\n",
       "      <td>ニューストップ&lt;SEP&gt;国内&lt;SEP&gt;社会</td>\n",
       "      <td>YouTuber&lt;SEP&gt;国内ニュース</td>\n",
       "      <td>6</td>\n",
       "      <td>日テレNEWS24</td>\n",
       "      <td>国内</td>\n",
       "      <td>元 ユーチューバー 、 「 へずまりゅう 」 こと 原田 将大 被告 ( 30 )――「( ...</td>\n",
       "      <td>へずまりゅう に 懲役 求刑 “ 反省 み られ ない \" \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://news.livedoor.com/article/detail/20558...</td>\n",
       "      <td>2021年7月19日 20時0分</td>\n",
       "      <td>【独自】Uターン失敗でパニックに？ 歩道や花壇に次々と突っ込む…ドラレコが捉えた謎の暴走事故</td>\n",
       "      <td>\\nスピードを上げ…歩道に突進ドライブレコーダーが捉えたのは、コントロールを失った車がスピー...</td>\n",
       "      <td>ニューストップ&lt;SEP&gt;国内</td>\n",
       "      <td>高齢ドライバーの事故&lt;SEP&gt;交通事故&lt;SEP&gt;国内の事件・事故</td>\n",
       "      <td>3</td>\n",
       "      <td>FNNプライムオンライン</td>\n",
       "      <td>国内</td>\n",
       "      <td>スピード を 上げ … 歩道 に 突進 ドライブレコーダー が 捉え た の は 、 コント...</td>\n",
       "      <td>【 独自 】 Uターン 失敗 で パニック に ? 歩道 や 花壇 に 次々 と 突っ込む ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://news.livedoor.com/article/detail/20558...</td>\n",
       "      <td>2021年7月19日 19時32分</td>\n",
       "      <td>小山田圭吾のいじめ告白記事『Quick Japan』出版元も謝罪　「差別を助長する不適切なもの」</td>\n",
       "      <td>\\n　ミュージシャンの小山田圭吾（52）が、学生時代に障がい者へのいじめを行っていたと告白し...</td>\n",
       "      <td>ニューストップ&lt;SEP&gt;芸能&lt;SEP&gt;芸能総合</td>\n",
       "      <td>小山田圭吾&lt;SEP&gt;東京五輪(2020)</td>\n",
       "      <td>358</td>\n",
       "      <td>オリコン</td>\n",
       "      <td>芸能</td>\n",
       "      <td>ミュージシャン の 小山田圭吾 ( 52 ) が 、 学生時代 に 障がい者 へ の いじめ...</td>\n",
       "      <td>小山田圭吾 の いじめ 告白 記事 『 Quick Japan 』 出版 元 も 謝罪 「 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://news.livedoor.com/article/detail/20555...</td>\n",
       "      <td>2021年7月19日 12時3分</td>\n",
       "      <td>韓国　日本大使館幹部処分を首脳会談条件に</td>\n",
       "      <td>\\n韓国の文在寅大統領の日本訪問と首脳会談について１９日、韓国側は、不適切な発言を行ったソウ...</td>\n",
       "      <td>ニューストップ&lt;SEP&gt;海外&lt;SEP&gt;海外総合</td>\n",
       "      <td>日韓首脳会談&lt;SEP&gt;日韓関係&lt;SEP&gt;韓国の話題&lt;SEP&gt;海外ニュース</td>\n",
       "      <td>28</td>\n",
       "      <td>日テレNEWS24</td>\n",
       "      <td>海外</td>\n",
       "      <td>韓国 の 文在寅 大統領 の 日本 訪問 と 首脳会談 について 19日 、 韓国側 は 、...</td>\n",
       "      <td>韓国 日本大使館 幹部 処分 を 首脳会談 条件 に \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url               date  \\\n",
       "0  https://news.livedoor.com/article/detail/20558...  2021年7月19日 19時40分   \n",
       "1  https://news.livedoor.com/article/detail/20558...  2021年7月19日 19時32分   \n",
       "2  https://news.livedoor.com/article/detail/20558...   2021年7月19日 20時0分   \n",
       "3  https://news.livedoor.com/article/detail/20558...  2021年7月19日 19時32分   \n",
       "4  https://news.livedoor.com/article/detail/20555...   2021年7月19日 12時3分   \n",
       "\n",
       "                                              title  \\\n",
       "0     安田大サーカス・クロちゃん、新型コロナ感染　団長安田とは「別ルートでの感染と考えられます」   \n",
       "1                              へずまりゅうに懲役求刑“反省みられない”   \n",
       "2    【独自】Uターン失敗でパニックに？ 歩道や花壇に次々と突っ込む…ドラレコが捉えた謎の暴走事故   \n",
       "3  小山田圭吾のいじめ告白記事『Quick Japan』出版元も謝罪　「差別を助長する不適切なもの」   \n",
       "4                              韓国　日本大使館幹部処分を首脳会談条件に   \n",
       "\n",
       "                                             context                 category  \\\n",
       "0  \\n　お笑いトリオ・安田大サーカスのクロちゃん（44）の所属事務所・松竹芸能は19日、クロち...  ニューストップ<SEP>芸能<SEP>芸能総合   \n",
       "1  \\n元ユーチューバー、「へずまりゅう」こと原田将大被告（３０）――「（Ｑ．初公判ですがお気持...    ニューストップ<SEP>国内<SEP>社会   \n",
       "2  \\nスピードを上げ…歩道に突進ドライブレコーダーが捉えたのは、コントロールを失った車がスピー...           ニューストップ<SEP>国内   \n",
       "3  \\n　ミュージシャンの小山田圭吾（52）が、学生時代に障がい者へのいじめを行っていたと告白し...  ニューストップ<SEP>芸能<SEP>芸能総合   \n",
       "4  \\n韓国の文在寅大統領の日本訪問と首脳会談について１９日、韓国側は、不適切な発言を行ったソウ...  ニューストップ<SEP>海外<SEP>海外総合   \n",
       "\n",
       "                                      keyword  tweet_share         quote  \\\n",
       "0  クロちゃん<SEP>安田大サーカス<SEP>芸能ニュース<SEP>新型コロナウイルス         1025          オリコン   \n",
       "1                         YouTuber<SEP>国内ニュース            6     日テレNEWS24   \n",
       "2            高齢ドライバーの事故<SEP>交通事故<SEP>国内の事件・事故            3  FNNプライムオンライン   \n",
       "3                        小山田圭吾<SEP>東京五輪(2020)          358          オリコン   \n",
       "4        日韓首脳会談<SEP>日韓関係<SEP>韓国の話題<SEP>海外ニュース           28     日テレNEWS24   \n",
       "\n",
       "  main_category                                           context_  \\\n",
       "0            芸能  お笑いトリオ ・ 安田大サーカス の クロちゃん ( 44 ) の 所属事務所 ・ 松竹芸能...   \n",
       "1            国内  元 ユーチューバー 、 「 へずまりゅう 」 こと 原田 将大 被告 ( 30 )――「( ...   \n",
       "2            国内  スピード を 上げ … 歩道 に 突進 ドライブレコーダー が 捉え た の は 、 コント...   \n",
       "3            芸能  ミュージシャン の 小山田圭吾 ( 52 ) が 、 学生時代 に 障がい者 へ の いじめ...   \n",
       "4            海外  韓国 の 文在寅 大統領 の 日本 訪問 と 首脳会談 について 19日 、 韓国側 は 、...   \n",
       "\n",
       "                                              title_  \n",
       "0  安田大サーカス ・ クロちゃん 、 新型 コロナ感染 団長安田 と は 「 別 ルート で ...  \n",
       "1                   へずまりゅう に 懲役 求刑 “ 反省 み られ ない \" \\n  \n",
       "2  【 独自 】 Uターン 失敗 で パニック に ? 歩道 や 花壇 に 次々 と 突っ込む ...  \n",
       "3  小山田圭吾 の いじめ 告白 記事 『 Quick Japan 』 出版 元 も 謝罪 「 ...  \n",
       "4                      韓国 日本大使館 幹部 処分 を 首脳会談 条件 に \\n  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../scraping/data/article.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c236aa-8a82-49e8-8057-7b078e264c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "国内              1500\n",
       "芸能              1212\n",
       "スポーツ            1007\n",
       "海外               989\n",
       "グルメ              894\n",
       "IT 経済            773\n",
       "ライフ総合            626\n",
       "ライフスタイル          373\n",
       "恋愛               341\n",
       "車                199\n",
       "ファッション・ビューティ     193\n",
       "Name: main_category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.main_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46335195-2913-40c2-8b89-544220beb414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.query(\"main_category == 'スポーツ'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de3bdc2f-cd0e-4b27-b894-354b34800c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     8107.000000\n",
      "mean       671.956827\n",
      "std        622.026574\n",
      "min         16.000000\n",
      "25%        283.000000\n",
      "50%        490.000000\n",
      "75%        834.000000\n",
      "max      10666.000000\n",
      "Name: context_, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 文の長さを固定するため\n",
    "print(df.context_.str.split().str.len().describe())\n",
    "df.context_.str.split().str.len().plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef8a3ed0-93fd-4739-9526-c6cdf04a656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    8107.000000\n",
      "mean       18.769335\n",
      "std         5.783181\n",
      "min         4.000000\n",
      "25%        15.000000\n",
      "50%        18.000000\n",
      "75%        22.000000\n",
      "max        51.000000\n",
      "Name: title_, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.title_.str.split().str.len().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1dc058f-aa26-4f99-b514-69638d30f236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8107,), (8107,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = df.context_.values\n",
    "title = df.title_.apply(lambda x: \"<BOS> \" + x + \" <EOS>\").values\n",
    "context.shape, title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec15626d-9355-436d-9b82-c35ffb070a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'お笑いトリオ ・ 安田大サーカス の クロちゃん ( 44 ) の 所属事務所 ・ 松竹芸能 は 19日 、 クロちゃん が 新型コロナウイルス に 感染 し た こと を 報告 し た 。 【 写真 】 1回目 の ワクチン 接種 後 に は … 体温計 の 写真 とともに 経過 を 報告 し た 団長安田 サイト で は 「 7月18日 夜 の 仕事 前 、 体調 に 違和感 と 悪寒 を 感じ た ため 、 体温 計測 し た ところ 37.5度 あり 、 発熱 外来 を 受診 、 新型コロナウイルス PCR検査 を 受け た 結果 、 同日 深夜 に 陽性 と 診断 さ れ まし た 」 と 説明 。 「 今後 は 保健所 の 指示 に従い 適切 に 対処 し て まいり ます 」 と し た 。 今月15日 に は 、 団長安田 ( 47 ) の 新型コロナウイルス 感染 を 公表 。 「 先日 感染 を ご 報告 さ せ て いただき まし た 、 団長安田 と は 直近 で の 接触 は なく 、 保健所 から も 濃厚接触者 に は 認定 さ れ て い ない 為 、 別 ルート で の 感染 と 考え られ ます 」 と 伝え 「 この 度 は 仕事 関係者 ・ 共演者 の 皆様 、 いつも 応援 し て 下さっ て いる 皆様 に 多大 なる ご 迷惑 と ご 心配 を お 掛け し て いる こと を 、 心より お詫び 申し上げ ます 」 と 記し た 。 最後 は 「 弊社 は 引き続き 、 行政機関 、 医療機関 の 指導 の もと 、 体調管理 の 徹底 、 所属 タレント および 社員 、 関係 各位 へ の 感染 防止 を 優先 し 、 新型コロナウイルス の 感染予防 、 拡大防止 対策 を 徹底 し て まいり ます 」 と コメント し て いる 。 \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c66797f-8dbc-430a-a87b-249e295a0400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS> 安田大サーカス ・ クロちゃん 、 新型 コロナ感染 団長安田 と は 「 別 ルート で の 感染 と 考え られ ます 」 \\n <EOS>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87f55129-0acc-48d8-8e4c-fc64982def53",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_tokenizer = pp.text.Tokenizer(filters=\"\", lower=False, oov_token=\"<UNK>\")\n",
    "keras_tokenizer.fit_on_texts(context.tolist()+title.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31631ddc-b84e-4be3-b56a-b6fbe4309565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127218"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keras_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee7ce94c-2f0e-49fe-83c8-49c08de8384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = keras_tokenizer.texts_to_sequences(context.tolist())\n",
    "y = keras_tokenizer.texts_to_sequences(title.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ae385e2-9876-454e-b284-2ac7ee367de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['お笑いトリオ', '・', '安田大サーカス', 'の', 'クロちゃん', '(', '44', ')', 'の', '所属事務所'],\n",
       " '->',\n",
       " ['<BOS>', '安田大サーカス', '・', 'クロちゃん', '、', '新型', 'コロナ感染', '団長安田', 'と', 'は'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[keras_tokenizer.index_word[idx] for idx in X[0][0:10]], \"->\" , [keras_tokenizer.index_word[idx] for idx in y[0][0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f764185b-e515-4261-bd26-6277dc0d9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pp.sequence.pad_sequences(X, maxlen=400, padding=\"post\", truncating=\"post\")\n",
    "y = pp.sequence.pad_sequences(y, maxlen=401, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaa7c9be-fd84-41ad-9da1-9bade138d413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8107, 400) (8107, 400) (8107, 400)\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs_X = X\n",
    "decoder_inputs_Y = y[:,:-1]\n",
    "decoder_outputs_Y = y[:,1:]\n",
    "print(encoder_inputs_X.shape, decoder_inputs_Y.shape, decoder_outputs_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67397e93-c877-440d-b86e-1623a3d76c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22983,    32, 30662,     2, 13463,    25,  5716,    28,     2,\n",
       "        3362,    32, 59765,     8,  1750,     3, 13463,     7,   468,\n",
       "           5,   380,    13,    10,    21,     6,   517,    13,    10,\n",
       "           4,    98,   116,    84,  2875,     2,   193,   213,   121,\n",
       "           5,     8,    49, 37386,     2,   116,   634,  3542,     6,\n",
       "         517,    13,    10, 26111,  1005,    11,     8,    14,  6488,\n",
       "         748,     2,   162,   119,     3,  2247,     5,  2481,    12,\n",
       "       49522,     6,   142,    10,    70,     3,  4140,  7397,    13,\n",
       "          10,   143, 37387,    45,     3,  4545, 21638,     6,  6755,\n",
       "           3,   468,  3527,     6,   190,    10,   236,     3,  2157,\n",
       "        1910,     5,  1534,    12,  2547,    29,    27,    38,    10,\n",
       "          15,    12,   306,     4,    14,   347,     8,  5799,     2,\n",
       "        1938, 12346,  2515,     5,  3328,    13,     9,  6568,    19,\n",
       "          15,    12,    13,    10,     4, 28176,     5,     8,     3,\n",
       "       26111,    25,  3457,    28,     2,   468,   380,     6,  1460,\n",
       "           4,    14,  2423,   380,     6,   145,   517,    29,   113,\n",
       "           9,   816,    38,    10,     3, 26111,    12,     8,  4824,\n",
       "          11,     2,  3151,     8,    71,     3,  5799,    26,    16,\n",
       "        4077,     5,     8,  2898,    29,    27,     9,    22,    23,\n",
       "        5849,     3,   348,  4108,    11,     2,   380,    12,   148,\n",
       "          65,    19,    15,    12,   355,    14,    48,   394,     8,\n",
       "         162,   438,    32,  9083,     2,  2177,     3,   571,  1011,\n",
       "          13,     9, 19563,     9,    18,  2177,     5,  8919,    50,\n",
       "         145,  1613,    12,   145,   690,     6,    81,  3349,    13,\n",
       "           9,    18,    21,     6,     3,  9397,  4039,  2965,    19,\n",
       "          15,    12,  3874,    10,     4,   362,     8,    14,  5248,\n",
       "           8,  2669,     3, 26112,     3,  5201,     2,  3039,     2,\n",
       "        1099,     3, 30663,     2,  2287,     3,  1157,  1150,  1885,\n",
       "        1126,     3,   232, 30664,    80,     2,   380,  1180,     6,\n",
       "        2313,    13,     3,   468,     2,  9084,     3, 19564,   392,\n",
       "           6,  2287,    13,     9,  6568,    19,    15,    12,   281,\n",
       "          13,     9,    18,     4,    35,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5cff1ed-a39d-47a8-b46f-c34de79946a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30662,    32, 13463,     3,   566,  5155, 26111,    12,     8,\n",
       "          14,   348,  4108,    11,     2,   380,    12,   148,    65,\n",
       "          19,    15,    35,    58,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs_Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66b7261a-bd8e-4e53-8ebc-a7a6e23dced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5649233f-e262-47bc-8cec-d1930f0f1deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method PositionalEmbedding.call of <__main__.PositionalEmbedding object at 0x2a76d4250>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method PositionalEmbedding.call of <__main__.PositionalEmbedding object at 0x2a76d4250>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TransformerEncoder.call of <__main__.TransformerEncoder object at 0x2a39c3d30>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TransformerEncoder.call of <__main__.TransformerEncoder object at 0x2a39c3d30>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TransformerDecoder.call of <__main__.TransformerDecoder object at 0x179249970>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TransformerDecoder.call of <__main__.TransformerDecoder object at 0x179249970>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 64\n",
    "latent_dim = 64\n",
    "num_heads = 2\n",
    "vocab_size = len(keras_tokenizer.word_index) + 1\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(400, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(400, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "375cecac-3a11-448d-86ad-238dce349a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positional_embedding (Positiona (None, None, 64)     8167616     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder (Transforme (None, None, 64)     41792       positional_embedding[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, None, 127219) 16511987    decoder_inputs[0][0]             \n",
      "                                                                 transformer_encoder[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 24,721,395\n",
      "Trainable params: 24,721,395\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67499d34-fc63-4f2c-b0c5-52d0b1cb8305",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27758a-8d00-4c0a-83fd-9fbe748177b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2a911e8b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2a911e8b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 20:53:48.186441: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-27 20:53:48.186650: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n",
      "2021-07-27 20:53:48.863565: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph transformer/positional_embedding/MLCSubgraphOp_0_13 with frame_id = 0 and iter_id = 0 with error: Invalid argument: Incompatible shapes: [64,400,64] vs. [1,400] (error will be reported 5 times unless TF_MLC_LOGGING=1).\n",
      "2021-07-27 20:53:48.863565: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph transformer/model_1/positional_embedding_1/MLCSubgraphOp_0_14 with frame_id = 0 and iter_id = 0 with error: Invalid argument: Incompatible shapes: [64,400,64] vs. [1,400] (error will be reported 5 times unless TF_MLC_LOGGING=1).\n"
     ]
    }
   ],
   "source": [
    "transformer.fit(x=(encoder_inputs_X, decoder_inputs_Y), y=decoder_outputs_Y, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e0ac093-6b26-46cb-b619-9ac0b81ecef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Trains the model for a fixed number of epochs (iterations on a dataset).\n",
       "\n",
       "Arguments:\n",
       "    x: Input data. It could be:\n",
       "      - A Numpy array (or array-like), or a list of arrays\n",
       "        (in case the model has multiple inputs).\n",
       "      - A TensorFlow tensor, or a list of tensors\n",
       "        (in case the model has multiple inputs).\n",
       "      - A dict mapping input names to the corresponding array/tensors,\n",
       "        if the model has named inputs.\n",
       "      - A `tf.data` dataset. Should return a tuple\n",
       "        of either `(inputs, targets)` or\n",
       "        `(inputs, targets, sample_weights)`.\n",
       "      - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
       "        or `(inputs, targets, sample_weights)`.\n",
       "      A more detailed description of unpacking behavior for iterator types\n",
       "      (Dataset, generator, Sequence) is given below.\n",
       "    y: Target data. Like the input data `x`,\n",
       "      it could be either Numpy array(s) or TensorFlow tensor(s).\n",
       "      It should be consistent with `x` (you cannot have Numpy inputs and\n",
       "      tensor targets, or inversely). If `x` is a dataset, generator,\n",
       "      or `keras.utils.Sequence` instance, `y` should\n",
       "      not be specified (since targets will be obtained from `x`).\n",
       "    batch_size: Integer or `None`.\n",
       "        Number of samples per gradient update.\n",
       "        If unspecified, `batch_size` will default to 32.\n",
       "        Do not specify the `batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.Sequence` instances\n",
       "        (since they generate batches).\n",
       "    epochs: Integer. Number of epochs to train the model.\n",
       "        An epoch is an iteration over the entire `x` and `y`\n",
       "        data provided.\n",
       "        Note that in conjunction with `initial_epoch`,\n",
       "        `epochs` is to be understood as \"final epoch\".\n",
       "        The model is not trained for a number of iterations\n",
       "        given by `epochs`, but merely until the epoch\n",
       "        of index `epochs` is reached.\n",
       "    verbose: 0, 1, or 2. Verbosity mode.\n",
       "        0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
       "        Note that the progress bar is not particularly useful when\n",
       "        logged to a file, so verbose=2 is recommended when not running\n",
       "        interactively (eg, in a production environment).\n",
       "    callbacks: List of `keras.callbacks.Callback` instances.\n",
       "        List of callbacks to apply during training.\n",
       "        See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
       "        and `tf.keras.callbacks.History` callbacks are created automatically\n",
       "        and need not be passed into `model.fit`.\n",
       "        `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
       "        `verbose` argument to `model.fit`.\n",
       "    validation_split: Float between 0 and 1.\n",
       "        Fraction of the training data to be used as validation data.\n",
       "        The model will set apart this fraction of the training data,\n",
       "        will not train on it, and will evaluate\n",
       "        the loss and any model metrics\n",
       "        on this data at the end of each epoch.\n",
       "        The validation data is selected from the last samples\n",
       "        in the `x` and `y` data provided, before shuffling. This argument is\n",
       "        not supported when `x` is a dataset, generator or\n",
       "       `keras.utils.Sequence` instance.\n",
       "    validation_data: Data on which to evaluate\n",
       "        the loss and any model metrics at the end of each epoch.\n",
       "        The model will not be trained on this data. Thus, note the fact\n",
       "        that the validation loss of data provided using `validation_split`\n",
       "        or `validation_data` is not affected by regularization layers like\n",
       "        noise and dropout.\n",
       "        `validation_data` will override `validation_split`.\n",
       "        `validation_data` could be:\n",
       "          - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
       "          - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
       "          - dataset\n",
       "        For the first two cases, `batch_size` must be provided.\n",
       "        For the last case, `validation_steps` could be provided.\n",
       "        Note that `validation_data` does not support all the data types that\n",
       "        are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
       "    shuffle: Boolean (whether to shuffle the training data\n",
       "        before each epoch) or str (for 'batch'). This argument is ignored\n",
       "        when `x` is a generator. 'batch' is a special option for dealing\n",
       "        with the limitations of HDF5 data; it shuffles in batch-sized\n",
       "        chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
       "    class_weight: Optional dictionary mapping class indices (integers)\n",
       "        to a weight (float) value, used for weighting the loss function\n",
       "        (during training only).\n",
       "        This can be useful to tell the model to\n",
       "        \"pay more attention\" to samples from\n",
       "        an under-represented class.\n",
       "    sample_weight: Optional Numpy array of weights for\n",
       "        the training samples, used for weighting the loss function\n",
       "        (during training only). You can either pass a flat (1D)\n",
       "        Numpy array with the same length as the input samples\n",
       "        (1:1 mapping between weights and samples),\n",
       "        or in the case of temporal data,\n",
       "        you can pass a 2D array with shape\n",
       "        `(samples, sequence_length)`,\n",
       "        to apply a different weight to every timestep of every sample. This\n",
       "        argument is not supported when `x` is a dataset, generator, or\n",
       "       `keras.utils.Sequence` instance, instead provide the sample_weights\n",
       "        as the third element of `x`.\n",
       "    initial_epoch: Integer.\n",
       "        Epoch at which to start training\n",
       "        (useful for resuming a previous training run).\n",
       "    steps_per_epoch: Integer or `None`.\n",
       "        Total number of steps (batches of samples)\n",
       "        before declaring one epoch finished and starting the\n",
       "        next epoch. When training with input tensors such as\n",
       "        TensorFlow data tensors, the default `None` is equal to\n",
       "        the number of samples in your dataset divided by\n",
       "        the batch size, or 1 if that cannot be determined. If x is a\n",
       "        `tf.data` dataset, and 'steps_per_epoch'\n",
       "        is None, the epoch will run until the input dataset is exhausted.\n",
       "        When passing an infinitely repeating dataset, you must specify the\n",
       "        `steps_per_epoch` argument. This argument is not supported with\n",
       "        array inputs.\n",
       "    validation_steps: Only relevant if `validation_data` is provided and\n",
       "        is a `tf.data` dataset. Total number of steps (batches of\n",
       "        samples) to draw before stopping when performing validation\n",
       "        at the end of every epoch. If 'validation_steps' is None, validation\n",
       "        will run until the `validation_data` dataset is exhausted. In the\n",
       "        case of an infinitely repeated dataset, it will run into an\n",
       "        infinite loop. If 'validation_steps' is specified and only part of\n",
       "        the dataset will be consumed, the evaluation will start from the\n",
       "        beginning of the dataset at each epoch. This ensures that the same\n",
       "        validation samples are used every time.\n",
       "    validation_batch_size: Integer or `None`.\n",
       "        Number of samples per validation batch.\n",
       "        If unspecified, will default to `batch_size`.\n",
       "        Do not specify the `validation_batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.Sequence` instances\n",
       "        (since they generate batches).\n",
       "    validation_freq: Only relevant if validation data is provided. Integer\n",
       "        or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
       "        If an integer, specifies how many training epochs to run before a\n",
       "        new validation run is performed, e.g. `validation_freq=2` runs\n",
       "        validation every 2 epochs. If a Container, specifies the epochs on\n",
       "        which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
       "        validation at the end of the 1st, 2nd, and 10th epochs.\n",
       "    max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
       "        input only. Maximum size for the generator queue.\n",
       "        If unspecified, `max_queue_size` will default to 10.\n",
       "    workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
       "        only. Maximum number of processes to spin up\n",
       "        when using process-based threading. If unspecified, `workers`\n",
       "        will default to 1. If 0, will execute the generator on the main\n",
       "        thread.\n",
       "    use_multiprocessing: Boolean. Used for generator or\n",
       "        `keras.utils.Sequence` input only. If `True`, use process-based\n",
       "        threading. If unspecified, `use_multiprocessing` will default to\n",
       "        `False`. Note that because this implementation relies on\n",
       "        multiprocessing, you should not pass non-picklable arguments to\n",
       "        the generator as they can't be passed easily to children processes.\n",
       "\n",
       "Unpacking behavior for iterator-like inputs:\n",
       "    A common pattern is to pass a tf.data.Dataset, generator, or\n",
       "  tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
       "  yield not only features (x) but optionally targets (y) and sample weights.\n",
       "  Keras requires that the output of such iterator-likes be unambiguous. The\n",
       "  iterator should return a tuple of length 1, 2, or 3, where the optional\n",
       "  second and third elements will be used for y and sample_weight\n",
       "  respectively. Any other type provided will be wrapped in a length one\n",
       "  tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
       "  should still adhere to the top-level tuple structure.\n",
       "  e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
       "  features, targets, and weights from the keys of a single dict.\n",
       "    A notable unsupported data type is the namedtuple. The reason is that\n",
       "  it behaves like both an ordered datatype (tuple) and a mapping\n",
       "  datatype (dict). So given a namedtuple of the form:\n",
       "      `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
       "  it is ambiguous whether to reverse the order of the elements when\n",
       "  interpreting the value. Even worse is a tuple of the form:\n",
       "      `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
       "  where it is unclear if the tuple was intended to be unpacked into x, y,\n",
       "  and sample_weight or passed through as a single element to `x`. As a\n",
       "  result the data processing code will simply raise a ValueError if it\n",
       "  encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
       "\n",
       "Returns:\n",
       "    A `History` object. Its `History.history` attribute is\n",
       "    a record of training loss values and metrics values\n",
       "    at successive epochs, as well as validation loss values\n",
       "    and validation metrics values (if applicable).\n",
       "\n",
       "Raises:\n",
       "    RuntimeError: 1. If the model was never compiled or,\n",
       "    2. If `model.fit` is  wrapped in `tf.function`.\n",
       "\n",
       "    ValueError: In case of mismatch between the provided input data\n",
       "        and what the model expects or when the input data is empty.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer.fit?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
