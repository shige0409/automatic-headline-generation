{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2296ea-960a-43a9-b2f8-b5ded398eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import utils\n",
    "\n",
    "from models.generater import load_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce56722f-f31a-4403-802e-64016d0e073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../scraping/data/datasets.bin\", 'rb') as f:\n",
    "    datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0ee9bd-0615-4e45-b9e4-1d4054c84385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['お笑いトリオ・安田大サーカスのクロちゃん(44)の所属事務所・松竹芸能は19日、クロちゃんが新型コロナウイルスに感染したことを報告した。【写真】1回目のワクチン接種後には…体温計の写真とともに経過を報告した団長安田サイトでは「7月18日夜の仕事前、体調に違和感と悪寒を感じたため、体温計測したところ37.5度あり、発熱外来を受診、新型コロナウイルスPCR検査を受けた結果、同日深夜に陽性と診断されました」と説明。「今後は保健所の指示に従い適切に対処してまいります」とした。今月15日には、団長安田(47)の新型コロナウイルス感染を公表。「先日感染をご報告させていただきました、団長安田とは直近での接触はなく、保健所からも濃厚接触者には認定されていない為、別ルートでの感染と考えられます」と伝え「この度は仕事関係者・共演者の皆様、いつも応援して下さっている皆様に多大なるご迷惑とご心配をお掛けしていることを、心よりお詫び申し上げます」と記した。最後は「弊社は引き続き、行政機関、医療機関の指導のもと、体調管理の徹底、所属タレントおよび社員、関係各位への感染防止を優先し、新型コロナウイルスの感染予防、拡大防止対策を徹底してまいります」とコメントしている。',\n",
       "       '安田大サーカス・クロちゃん、新型コロナ感染団長安田とは「別ルートでの感染と考えられます」'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8381b6-c601-4e63-9131-e90ba1a35995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Encoder.call of <models.transformer.Encoder object at 0x151235d90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Encoder.call of <models.transformer.Encoder object at 0x151235d90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <models.transformer.MultiHeadAttention object at 0x1526b1490>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MultiHeadAttention.call of <models.transformer.MultiHeadAttention object at 0x1526b1490>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Decoder.call of <models.transformer.Decoder object at 0x151235df0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Decoder.call of <models.transformer.Decoder object at 0x151235df0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer, keras_tokenizer = utils.load_tokenizer()\n",
    "tf_tranformer = load_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba3a93d-c173-44de-88d6-dbd05e7b7fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import mojimoji\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from models.config import *\n",
    "from models.transformer import Transformer, create_masks\n",
    "\n",
    "import tensorflow.nn as nn\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import preprocessing as pp\n",
    "\n",
    "from transformers import BertJapaneseTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28863e9d-89a1-4cf5-9b4f-18f1c750f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_title(text, models, beam_width = 3):\n",
    "    bt, kt, model = models\n",
    "    decoder_sentence = \"[BOS]\"\n",
    "    input_sentence = \" \".join(bt.tokenize(text))\n",
    "    encoder_sentence_ = kt.texts_to_sequences([input_sentence])\n",
    "    encoder_sentence_ = pp.sequence.pad_sequences(encoder_sentence_, maxlen=ENC_SEQ_LEN, padding=\"post\", truncating=\"post\")\n",
    "    for i in range(50):\n",
    "        decoder_sentence_ = kt.texts_to_sequences([decoder_sentence])\n",
    "        decoder_sentence_ = pp.sequence.pad_sequences(decoder_sentence_, maxlen=DEC_SEQ_LEN, padding=\"post\", truncating=\"post\")\n",
    "        pred = model((encoder_sentence_, decoder_sentence_))\n",
    "        sampled_tkn_idx = np.argmax(pred[0,i,:])\n",
    "        sampled_tkn = kt.index_word[sampled_tkn_idx]\n",
    "        decoder_sentence =  decoder_sentence + \" \" + sampled_tkn\n",
    "        if sampled_tkn == \"[EOS]\":\n",
    "            break\n",
    "    return \"\".join(re.sub(\"#\", \"\", decoder_sentence).split(\" \")[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45d9d514-1fad-48bb-af9d-49098421f46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'安田大サーカス・クロちゃん、新型コロナ感染団長安田とは「別ルートでの感染と考えられない」'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_title(datasets[0][0], [bert_tokenizer, keras_tokenizer, tf_tranformer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657361ea-81ad-4d45-a686-b5a8f169a2c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ここからビームサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "769bdf86-dbf6-4b23-8006-898eb9bb651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = datasets[0][0]\n",
    "\n",
    "idx = 0\n",
    "beam_width = 3\n",
    "pre_log_prob = np.array([[0.]]*beam_width)\n",
    "decoder_sentence = [\"[BOS]\"] * beam_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27fbe673-b13b-4934-b0da-36f0061f3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = [\" \".join(bert_tokenizer.tokenize(text))] * beam_width\n",
    "encoder_sentence_ = keras_tokenizer.texts_to_sequences(input_sentence)\n",
    "encoder_sentence_ = pp.sequence.pad_sequences(encoder_sentence_, maxlen=ENC_SEQ_LEN, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3c08774-ea1d-4eb8-8184-d7e12daa79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここから繰り返し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d0cfbaa2-1508-4bd4-ab6d-8cb7e23ab696",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_sentence_ = keras_tokenizer.texts_to_sequences(decoder_sentence)\n",
    "decoder_sentence_ = pp.sequence.pad_sequences(decoder_sentence_, maxlen=DEC_SEQ_LEN, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b6a88744-cf7f-4414-abc0-a75216314914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   69, 10507,   121,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [   69,   598,   177,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [   69,   177,  1503,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]], dtype=int32),\n",
       " (3, 50))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sentence_, decoder_sentence_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7904e444-e831-4db2-8cef-62c3250a8a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 1400), (3, 50))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_sentence_.shape, decoder_sentence_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f1b58de7-371a-44c6-a086-47bb97c58f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 50, 28363])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tf_tranformer((encoder_sentence_, decoder_sentence_))\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bfe90636-75ab-4a70-be4d-445fa2ccaf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_pred = np.log(nn.softmax(pred, axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "99df99a6-43bc-4307-a65f-e96af893ac3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 50, 28363),\n",
       " array([[[-39.567787 , -17.069489 , -16.214853 , ..., -37.158997 ,\n",
       "          -40.21804  , -31.589146 ],\n",
       "         [-36.435406 ,  -9.215334 , -10.416154 , ..., -34.65623  ,\n",
       "          -35.44389  , -30.687515 ],\n",
       "         [-39.18754  , -16.806036 , -14.252772 , ..., -34.777824 ,\n",
       "          -43.412247 , -34.307888 ],\n",
       "         ...,\n",
       "         [-30.912405 , -11.96753  ,  -9.817523 , ..., -22.729021 ,\n",
       "          -33.868515 , -25.0241   ],\n",
       "         [-29.220476 , -13.061031 , -11.547819 , ..., -23.225607 ,\n",
       "          -31.188604 , -26.660381 ],\n",
       "         [-28.877745 ,  -9.493163 ,  -9.201644 , ..., -21.445559 ,\n",
       "          -31.768745 , -22.333199 ]],\n",
       " \n",
       "        [[-37.57273  , -18.11583  , -14.9006195, ..., -37.140236 ,\n",
       "          -37.492783 , -32.667576 ],\n",
       "         [-34.931744 , -15.42896  , -14.452543 , ..., -31.06536  ,\n",
       "          -39.687    , -31.245728 ],\n",
       "         [-28.572104 ,  -9.307538 , -10.547096 , ..., -27.821558 ,\n",
       "          -35.897892 , -18.747347 ],\n",
       "         ...,\n",
       "         [-25.312113 , -10.131409 ,  -4.913844 , ..., -16.776463 ,\n",
       "          -35.508724 , -26.05344  ],\n",
       "         [-26.754284 , -11.713031 ,  -4.4951777, ..., -19.250574 ,\n",
       "          -33.853817 , -21.562405 ],\n",
       "         [-26.596664 ,  -8.577361 ,  -4.6157637, ..., -20.141253 ,\n",
       "          -34.831264 , -24.922956 ]],\n",
       " \n",
       "        [[-37.25397  , -16.664618 , -15.166368 , ..., -36.59687  ,\n",
       "          -35.549004 , -31.735407 ],\n",
       "         [-38.524063 , -15.281837 , -16.328243 , ..., -40.518257 ,\n",
       "          -38.803917 , -30.607496 ],\n",
       "         [-30.199045 ,  -6.5583663,  -9.2403755, ..., -26.14892  ,\n",
       "          -33.326813 , -22.7043   ],\n",
       "         ...,\n",
       "         [-29.956553 ,  -7.8499413,  -7.855809 , ..., -27.786472 ,\n",
       "          -34.659073 , -23.732141 ],\n",
       "         [-29.723936 , -12.156151 , -11.696916 , ..., -28.002098 ,\n",
       "          -31.990551 , -22.88536  ],\n",
       "         [-27.501402 , -10.597284 , -10.240011 , ..., -26.076813 ,\n",
       "          -31.37731  , -20.774424 ]]], dtype=float32))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_pred.shape, log_prob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "386c1c73-2453-463e-b4fa-87f18fc72aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 28363)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_pred = log_prob_pred[:,idx,:]\n",
    "log_prob_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c224a39b-2e42-4484-8a9b-bae05243843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_log_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed35e1c9-71a9-4623-8108-06e37bd9656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_pred = pre_log_prob + log_prob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48dc5f04-8154-4ee2-82b5-8767c71fc82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 28363)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c9d975d-2363-498d-8245-1e0bb32ddae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の生成だけ\n",
    "if idx == 0:\n",
    "    log_prob_pred = log_prob_pred[idx:idx+1]\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7d1e2172-1498-467b-a60c-348d7656bb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20391,  3181, 10180])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_log_prob_idx_with_beam = np.argsort(-log_prob_pred.reshape(-1))[:beam_width]\n",
    "max_log_prob_idx_with_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc3b7bbc-1078-4cb5-86b8-a54318e78eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 20391), (0, 3181), (0, 10180)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_log_prob_idx_with_beam = [divmod(idx, 28363) for idx in max_log_prob_idx_with_beam]\n",
    "max_log_prob_idx_with_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "864815e4-24bd-42a0-ae11-c822dfe87a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.021259089757222682, -8.28830946306698, -8.643027671379969]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob = [log_prob_pred[beam_idx, vocab_idx] for beam_idx, vocab_idx in max_log_prob_idx_with_beam]\n",
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "addfece0-56ce-488b-9a79-cd32bfdc671f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.04181018],\n",
       "       [-20.9342675 ],\n",
       "       [-23.42600725]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_log_prob += np.array(log_prob)[:,np.newaxis]\n",
    "pre_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2fe0b762-aefe-41d3-87bf-5f7b57375b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['サーカス', '##瀬', '健二']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_words = [keras_tokenizer.index_word[vocab_idx] for _, vocab_idx in max_log_prob_idx_with_beam]\n",
    "add_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0c867c8-35dc-4c03-b5d7-dd2ec9fb30c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BOS] 安田 大 サーカス', '[BOS] 23 コロナ ##瀬', '[BOS] コロナ ホテル 健二']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sentence = [t1 + \" \" + t2 for t1, t2 in zip(decoder_sentence, add_words)]\n",
    "decoder_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9b2ccce6-39be-44d6-bd3e-5ba7e16cb7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx += 1\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b33997-e3bb-43ba-b638-a41fba272e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
